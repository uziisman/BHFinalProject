{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d20f68-9488-434c-bb77-a4400b4a85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import h5py\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set base URL and headers for the TNG API\n",
    "baseUrl = 'http://www.tng-project.org/api/'\n",
    "headers = {\"api-key\": \"128de4248c745e040927ee558a9bcd62\"}\n",
    "\n",
    "def get(url, params=None):\n",
    "    r = requests.get(url, params=params, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json()\n",
    "    return r\n",
    "\n",
    "def get_data(url, params=None):\n",
    "    \"\"\"\n",
    "    Download cutout data from the given URL.\n",
    "    Returns the filename if a file is downloaded.\n",
    "    \"\"\"\n",
    "    r = requests.get(url, params=params, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json()\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return filename\n",
    "    return r\n",
    "\n",
    "def search_mergers(mergers, bhid):\n",
    "    \"\"\"\n",
    "    Given a structured array 'mergers' and a black hole ID (bhid),\n",
    "    return the rows where either id1 or id2 equals the BH id.\n",
    "    \"\"\"\n",
    "    mask = mergers['id1'] == bhid\n",
    "    mask |= mergers['id2'] == bhid\n",
    "    return mergers[mask]\n",
    "\n",
    "def frequency(m1, m2, z):\n",
    "    \"\"\"\n",
    "    Compute the frequency based on the formula:\n",
    "      frequency = 3.9 * ((10**4) / (m1 + m2)) * (1/(1+z))\n",
    "    m1 and m2 are in solar masses and z is the redshift.\n",
    "    \"\"\"\n",
    "    m = m1 + m2\n",
    "    return 3.9 * ((10**4) / m) * (1 / (1 + z))\n",
    "\n",
    "# Define the allowed redshifts (13 values)\n",
    "allowed_redshifts = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "\n",
    "# Load merger data (ensure that 'TNG100_mergers_withID.npy' exists in your working directory)\n",
    "data_dir = \"./\"\n",
    "tng100_mergers = np.load(data_dir + 'TNG100_mergers_withID.npy')\n",
    "\n",
    "# Get simulation info for TNG100-1\n",
    "r = get(baseUrl)\n",
    "names = [sim['name'] for sim in r['simulations']]\n",
    "i = names.index('TNG100-1')\n",
    "sim = get(r['simulations'][i]['url'])\n",
    "\n",
    "# Retrieve snapshots\n",
    "snaps = get(sim['url'] + 'snapshots/')\n",
    "\n",
    "# Select a snapshot of interest (we assume the snapshot dict uses key 'number')\n",
    "snap_num = 50\n",
    "snap_list = [s for s in snaps if s.get('number') == snap_num]\n",
    "if not snap_list:\n",
    "    raise ValueError(\"Snapshot number %d not found.\" % snap_num)\n",
    "snap = snap_list[0]\n",
    "\n",
    "# Retrieve all subhalo data for the snapshot using pagination\n",
    "subhalos = []\n",
    "sub_url = snap['url'] + 'subhalos/'\n",
    "params = {'limit': 100, 'order_by': '-mass_stars'}\n",
    "while sub_url:\n",
    "    sub_data = get(sub_url, params)\n",
    "    subhalos.extend(sub_data['results'])\n",
    "    sub_url = sub_data.get('next')\n",
    "    params = None  # subsequent pages already include the parameters\n",
    "\n",
    "# Define the Hubble constant for unit conversion (use TNG value, e.g., 0.6774)\n",
    "hubble = 0.6774\n",
    "\n",
    "def process_subhalo(sub):\n",
    "    \"\"\"\n",
    "    Process a single subhalo: get its largest BH, retrieve its cutout,\n",
    "    and search for merger events.\n",
    "    Returns a dict with subhalo info and allowed redshifts found,\n",
    "    or None if something fails.\n",
    "    \"\"\"\n",
    "    sub_id = sub['id']\n",
    "    sub_url = f\"{snap['url']}subhalos/{sub_id}/\"\n",
    "    cutout_request = {'bhs': 'ParticleIDs,Masses'}\n",
    "    try:\n",
    "        cutout_file = get_data(sub_url + \"cutout.hdf5\", cutout_request)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with h5py.File(cutout_file, 'r') as f:\n",
    "            bh_ids = f['PartType5']['ParticleIDs'][:]\n",
    "            bh_masses = f['PartType5']['Masses'][:] * 1e10 / hubble  # Convert to solar masses\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if len(bh_masses) == 0:\n",
    "        return None\n",
    "\n",
    "    # Find the most massive BH and get its ID\n",
    "    max_index = np.argmax(bh_masses)\n",
    "    largest_bh_id = bh_ids[max_index]\n",
    "\n",
    "    mergers_this_bh = search_mergers(tng100_mergers, largest_bh_id)\n",
    "    if len(mergers_this_bh) == 0:\n",
    "        return None\n",
    "\n",
    "    # Record which allowed redshifts are encountered\n",
    "    redshifts_found = {round(m['redshift'], 1) for m in mergers_this_bh if round(m['redshift'], 1) in allowed_redshifts}\n",
    "\n",
    "    return {\n",
    "         'subhalo_id': sub_id,\n",
    "         'bh_id': largest_bh_id,\n",
    "         'mergers': mergers_this_bh,\n",
    "         'redshifts': redshifts_found\n",
    "    }\n",
    "\n",
    "# Use a thread pool to process subhalos concurrently.\n",
    "bh_merger_info = []\n",
    "collected_redshifts = set()\n",
    "\n",
    "# You can adjust max_workers; too many threads might overload your connection.\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_subhalo, sub): sub for sub in subhalos}\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            bh_merger_info.append(result)\n",
    "            collected_redshifts.update(result['redshifts'])\n",
    "        # If we've already collected all allowed redshifts, we can optionally break early.\n",
    "        if len(collected_redshifts) == len(allowed_redshifts):\n",
    "            break\n",
    "\n",
    "# Create a dictionary to collect frequencies for each allowed redshift\n",
    "freq_dict = {z: [] for z in allowed_redshifts}\n",
    "\n",
    "# Process each merger event and store the frequency if the redshift is allowed\n",
    "for info in bh_merger_info:\n",
    "    for merger in info['mergers']:\n",
    "        merger_z = round(merger['redshift'], 1)\n",
    "        if merger_z in allowed_redshifts:\n",
    "            f = frequency(merger['m1'], merger['m2'], merger_z)\n",
    "            freq_dict[merger_z].append(f)\n",
    "\n",
    "# Compute the average frequency for each allowed redshift\n",
    "avg_freqs = []\n",
    "for z in allowed_redshifts:\n",
    "    if freq_dict[z]:\n",
    "        avg_freqs.append(np.mean(freq_dict[z]))\n",
    "    else:\n",
    "        avg_freqs.append(np.nan)\n",
    "\n",
    "# Plot Average Frequency vs Redshift\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.semilogy(allowed_redshifts, avg_freqs, 'ro-', markersize=8)\n",
    "plt.xlabel(\"Redshift (z)\")\n",
    "plt.ylabel(\"Average Frequency (Hz)\")\n",
    "plt.title(\"Average Merger Frequency vs Redshift\")\n",
    "plt.xticks(allowed_redshifts)  # Label the x-axis with all 13 redshift values\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.savefig(\"average_merger_frequency_redshift.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d94ea-596c-4f57-8187-d14d20df7b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
